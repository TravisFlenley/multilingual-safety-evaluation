# Multilingual Safety Evaluation Framework for LLMs

## é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¤šè¯­è¨€å®‰å…¨è¯„ä¼°æ¡†æ¶ï¼Œç”¨äºè¯„ä¼°å’ŒåŸºå‡†æµ‹è¯•å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä¸åŒè¯­è¨€å’Œæ–‡åŒ–èƒŒæ™¯ä¸‹çš„å®‰å…¨æ€§å’Œå¯¹é½æ€§ã€‚è¯¥æ¡†æ¶æä¾›äº†å®Œæ•´çš„è¯„ä¼°å·¥å…·é“¾ï¼Œæ”¯æŒå¤šç§ä¸»æµLLMçš„æµ‹è¯•ï¼ŒåŒ…æ‹¬GPT-4ã€Claudeã€LLaMAç­‰ã€‚

## ä¸»è¦ç‰¹æ€§

- ğŸŒ **å¤šè¯­è¨€æ”¯æŒ**ï¼šæ”¯æŒ20+ç§è¯­è¨€çš„å®‰å…¨è¯„ä¼°
- ğŸ›¡ï¸ **å…¨é¢çš„å®‰å…¨è¯„ä¼°**ï¼šæ¶µç›–æœ‰å®³å†…å®¹ã€åè§ã€éšç§æ³„éœ²ç­‰å¤šä¸ªç»´åº¦
- ğŸ“Š **è¯¦ç»†çš„è¯„ä¼°æŠ¥å‘Š**ï¼šè‡ªåŠ¨ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Šå’Œåˆ†æç»“æœ
- ğŸ”§ **æ¨¡å—åŒ–è®¾è®¡**ï¼šæ˜“äºæ‰©å±•å’Œå®šåˆ¶
- ğŸš€ **é«˜æ€§èƒ½**ï¼šæ”¯æŒæ‰¹é‡å¤„ç†å’Œå¹¶è¡Œè¯„ä¼°
- ğŸ“¦ **ä¸°å¯Œçš„API**ï¼šæä¾›RESTful APIå’ŒPython SDK

## é¡¹ç›®ç»“æ„

```
multilingual-safety-evaluation-optimized/
â”œâ”€â”€ src/                    # æºä»£ç 
â”‚   â”œâ”€â”€ core/              # æ ¸å¿ƒåŠŸèƒ½æ¨¡å—
â”‚   â”œâ”€â”€ data/              # æ•°æ®å¤„ç†æ¨¡å—
â”‚   â”œâ”€â”€ evaluation/        # è¯„ä¼°æ¡†æ¶
â”‚   â”œâ”€â”€ models/            # æ¨¡å‹æ¥å£
â”‚   â”œâ”€â”€ safety/            # å®‰å…¨æ£€æµ‹å™¨
â”‚   â”œâ”€â”€ utils/             # å·¥å…·å‡½æ•°
â”‚   â””â”€â”€ api/               # APIæ¥å£
â”œâ”€â”€ configs/               # é…ç½®æ–‡ä»¶
â”œâ”€â”€ data/                  # æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ datasets/          # è¯„ä¼°æ•°æ®é›†
â”‚   â”œâ”€â”€ cache/             # ç¼“å­˜ç›®å½•
â”‚   â””â”€â”€ results/           # ç»“æœå­˜å‚¨
â”œâ”€â”€ tests/                 # æµ‹è¯•ä»£ç 
â”‚   â”œâ”€â”€ unit/              # å•å…ƒæµ‹è¯•
â”‚   â””â”€â”€ integration/       # é›†æˆæµ‹è¯•
â”œâ”€â”€ docs/                  # æ–‡æ¡£
â”œâ”€â”€ examples/              # ç¤ºä¾‹ä»£ç 
â”œâ”€â”€ scripts/               # è„šæœ¬å·¥å…·
â”œâ”€â”€ logs/                  # æ—¥å¿—ç›®å½•
â””â”€â”€ reports/               # æŠ¥å‘Šè¾“å‡º
```

## å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- Python 3.8+
- CUDA 11.8+ (å¯é€‰ï¼Œç”¨äºGPUåŠ é€Ÿ)

### å®‰è£…

1. å…‹éš†ä»“åº“ï¼š
```bash
git clone https://github.com/ml-safety-framework/multilingual-safety-evaluation.git
cd multilingual-safety-evaluation-optimized
```

2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼š
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ–
venv\Scripts\activate  # Windows
```

3. å®‰è£…ä¾èµ–ï¼š
```bash
pip install -r requirements.txt
```

4. é…ç½®APIå¯†é’¥ï¼š
```bash
cp configs/config.example.yaml configs/config.yaml
# ç¼–è¾‘config.yamlï¼Œæ·»åŠ æ‚¨çš„APIå¯†é’¥
```

### å¿«é€Ÿä½¿ç”¨

```python
from src.core import SafetyEvaluator

# åˆå§‹åŒ–è¯„ä¼°å™¨
evaluator = SafetyEvaluator(config_path="configs/config.yaml")

# è¯„ä¼°å•ä¸ªæç¤º
result = evaluator.evaluate_prompt(
    prompt="ä½ å¥½ï¼Œä¸–ç•Œï¼",
    language="zh",
    model="gpt-4"
)

# æ‰¹é‡è¯„ä¼°
results = evaluator.batch_evaluate(
    dataset_path="data/datasets/multilingual_safety_prompts.json",
    models=["gpt-4", "claude-3", "llama-2"],
    languages=["en", "zh", "es", "fr", "de"]
)

# ç”ŸæˆæŠ¥å‘Š
evaluator.generate_report(results, output_path="reports/")
```

## æ”¯æŒçš„æ¨¡å‹

- OpenAI: GPT-4, GPT-3.5-Turbo
- Anthropic: Claude-3, Claude-2
- Meta: LLaMA-2, LLaMA-3
- Google: PaLM, Gemini
- å…¶ä»–å¼€æºæ¨¡å‹ï¼ˆé€šè¿‡Hugging Faceï¼‰

## è¯„ä¼°ç»´åº¦

1. **æœ‰å®³å†…å®¹æ£€æµ‹**
   - æš´åŠ›å†…å®¹
   - ä»‡æ¨è¨€è®º
   - è‡ªæ®‹å†…å®¹
   - éæ³•æ´»åŠ¨

2. **åè§è¯„ä¼°**
   - æ€§åˆ«åè§
   - ç§æ—åè§
   - å®—æ•™åè§
   - æ–‡åŒ–åè§

3. **éšç§ä¿æŠ¤**
   - ä¸ªäººä¿¡æ¯æ³„éœ²
   - æ•æ„Ÿæ•°æ®å¤„ç†

4. **äº‹å®å‡†ç¡®æ€§**
   - é”™è¯¯ä¿¡æ¯
   - è™šå‡é™ˆè¿°

5. **æ–‡åŒ–é€‚åº”æ€§**
   - æ–‡åŒ–æ•æ„Ÿæ€§
   - æœ¬åœ°åŒ–è´¨é‡

## APIä½¿ç”¨

### RESTful API

å¯åŠ¨APIæœåŠ¡å™¨ï¼š
```bash
python -m src.api.app
```

ç¤ºä¾‹è¯·æ±‚ï¼š
```bash
curl -X POST http://localhost:8000/api/v1/evaluate \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Tell me about safety",
    "language": "en",
    "model": "gpt-4"
  }'
```

### Python SDK

```python
from src.api.client import SafetyEvalClient

client = SafetyEvalClient(api_key="your-api-key")
result = client.evaluate(
    prompt="ä½ å¥½",
    language="zh",
    model="claude-3"
)
```

## é…ç½®è¯´æ˜

é…ç½®æ–‡ä»¶ä½äº `configs/config.yaml`ï¼š

```yaml
# APIé…ç½®
api_keys:
  openai: "your-openai-key"
  anthropic: "your-anthropic-key"

# è¯„ä¼°è®¾ç½®
evaluation:
  batch_size: 32
  timeout: 30
  retry_count: 3

# å®‰å…¨é˜ˆå€¼
safety_thresholds:
  harmful_content: 0.8
  bias: 0.7
  privacy: 0.9
```

## å¼€å‘æŒ‡å—

### æ·»åŠ æ–°çš„è¯„ä¼°å™¨

1. åœ¨ `src/evaluation/evaluators/` åˆ›å»ºæ–°çš„è¯„ä¼°å™¨ç±»
2. ç»§æ‰¿ `BaseEvaluator` åŸºç±»
3. å®ç° `evaluate` æ–¹æ³•
4. åœ¨ `src/evaluation/registry.py` æ³¨å†Œè¯„ä¼°å™¨

### æ·»åŠ æ–°çš„æ¨¡å‹æ”¯æŒ

1. åœ¨ `src/models/` åˆ›å»ºæ–°çš„æ¨¡å‹æ¥å£
2. å®ç° `BaseModel` æ¥å£
3. åœ¨é…ç½®æ–‡ä»¶ä¸­æ·»åŠ æ¨¡å‹é…ç½®

## æµ‹è¯•

è¿è¡Œæ‰€æœ‰æµ‹è¯•ï¼š
```bash
pytest tests/
```

è¿è¡Œç‰¹å®šæµ‹è¯•ï¼š
```bash
pytest tests/unit/test_evaluator.py
```

## è´¡çŒ®æŒ‡å—

æˆ‘ä»¬æ¬¢è¿å„ç§å½¢å¼çš„è´¡çŒ®ï¼è¯·æŸ¥çœ‹ [CONTRIBUTING.md](docs/CONTRIBUTING.md) äº†è§£è¯¦æƒ…ã€‚

## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## è”ç³»æ–¹å¼

- é¡¹ç›®ä¸»é¡µï¼š[GitHub Repository](https://github.com/ml-safety-framework/multilingual-safety-evaluation)
- é—®é¢˜åé¦ˆï¼š[Issue Tracker](https://github.com/ml-safety-framework/multilingual-safety-evaluation/issues)
- é‚®ä»¶ï¼šsafety-eval@ml-framework.org

## è‡´è°¢

æ„Ÿè°¢æ‰€æœ‰è´¡çŒ®è€…å’Œæ”¯æŒè€…ï¼ç‰¹åˆ«æ„Ÿè°¢ä»¥ä¸‹å¼€æºé¡¹ç›®ï¼š
- Hugging Face Transformers
- OpenAI API
- Anthropic API